{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"../input/train.csv\")\n",
    "test_set = pd.read_csv(\"../input/test.csv\")\n",
    "train_set.drop(train_set[(train_set['GrLivArea']>4000) & (train_set['SalePrice']<300000)].index, inplace=True)\n",
    "train_set.drop(train_set[(train_set['GarageArea']>1200) & (train_set['SalePrice']<100000)].index, inplace=True)\n",
    "train_set.drop(train_set[(train_set['TotalBsmtSF']>6000) & (train_set['SalePrice']<200000)].index, inplace=True)\n",
    "y_train = train_set.SalePrice\n",
    "\n",
    "train_set = train_set.drop([\"SalePrice\"], axis=1)\n",
    "train_set = train_set.set_index('Id')\n",
    "test_set = test_set.set_index('Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3799759db3eb279d2ce5970da8c098f554566148",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weak=['BedroomAbvGr', 'ScreenPorch', 'PoolArea', 'MoSold', '3SsnPorch',\n",
    "       'BsmtFinSF2', 'BsmtHalfBath', 'MiscVal', 'LowQualFinSF', 'YrSold',\n",
    "       'OverallCond', 'MSSubClass', 'EnclosedPorch', 'KitchenAbvGr']\n",
    "train_set.drop(weak, axis=1, inplace=True)\n",
    "test_set.drop(weak, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0e8446747ee7125756370e5d0baa9e6db39b255",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "firstmerge = pd.concat([train_set, test_set], axis=0)\n",
    "data_dummies= pd.get_dummies(firstmerge)\n",
    "data_dummies = data_dummies.reset_index(drop=True)\n",
    "train_set = data_dummies.loc[0:1456]\n",
    "test_set = data_dummies.loc[1457:]\n",
    "my_imputer = SimpleImputer()\n",
    "train_set = my_imputer.fit_transform(train_set)\n",
    "test_set = my_imputer.fit_transform(test_set)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_set)\n",
    "train_scaled = scaler.transform(train_set)\n",
    "test_scaled = scaler.transform(test_set)\n",
    "\n",
    "y_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stacked Regression with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# lr = LinearRegression()\n",
    "# svr_lin = SVR(kernel='linear')\n",
    "# ridge = Ridge(random_state=1)\n",
    "# lasso = Lasso(random_state=1)\n",
    "# svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "\n",
    "# params = {'lasso__alpha': [0.1, 1.0],\n",
    "#           'ridge__alpha': [0.1, 1.0],\n",
    "#           'svr__C': [0.1, 1.0],\n",
    "#           'meta-svr__C': [0.1, 1.0],\n",
    "#           'meta-svr__gamma': [0.1, 1.0]}\n",
    "\n",
    "\n",
    "# stregr = StackingRegressor(regressors=[svr_lin, lr, ridge, lasso], \n",
    "#                            meta_regressor=svr_rbf, verbose=1)\n",
    "# grid = GridSearchCV(estimator=stregr, \n",
    "#                     param_grid=params, \n",
    "#                     cv=5,\n",
    "#                     refit=True)\n",
    "# grid.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Regression w/o GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# GBoost = GradientBoostingRegressor(n_estimators=5000, learning_rate=0.005,\n",
    "#                                    max_depth=4, max_features='sqrt',\n",
    "#                                    min_samples_leaf=15, min_samples_split=10, \n",
    "#                                    loss='huber', random_state =5)\n",
    "# lr = LinearRegression()\n",
    "# svr_lin = SVR(kernel='linear')\n",
    "# ridge = Ridge(random_state=1)\n",
    "# svr_rbf = SVR(kernel='rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# stregr = StackingRegressor(regressors=[svr_lin, lr, ridge, GBoost], \n",
    "#                            meta_regressor=svr_rbf)\n",
    "\n",
    "# # Training the stacking classifier\n",
    "\n",
    "# stregr.fit(train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bag_reg = BaggingRegressor(GradientBoostingRegressor(learning_rate=0.005,\n",
    "#                                 max_depth=4, max_features='sqrt',\n",
    "#                                 min_samples_leaf=15, min_samples_split=10, \n",
    "#                                 loss='huber', random_state =5, n_estimators=400), n_estimators=500, max_samples=100, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bag_reg.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n           max_features='sqrt', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=None,\n           oob_score=False, random_state=None, verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rnd_clf = RandomForestRegressor(n_estimators=2500, max_depth=3, max_features='sqrt', warm_start=True, verbose=1)\n",
    "# rnd_clf.fit(train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=5000, learning_rate=0.001,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GBoost.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "619e30a8f186a40510a94e3bcb1701c879006366",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_result = GBoost.predict(test_scaled)\n",
    "test_result = np.exp(test_result)-1\n",
    "df= pd.DataFrame({'SalePrice': test_result})\n",
    "df.index.name='Id'\n",
    "df.index +=1461\n",
    "df.to_csv('gridsearch.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
